{"version":3,"file":"tokenise.js","sourceRoot":"","sources":["../src/tokenise.ts"],"names":[],"mappings":";;AAAA,MAAM,IAAI,GAA4B,QAAQ,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,CAAA;AAC3E,MAAM,WAAW,GAAG,CAAC,EAAU,EAAU,EAAE;IAC1C,IAAI,GAAG,GAAG,EAAE,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IAC3B,IAAI,GAAG,KAAK,CAAC,CAAC;QAAE,OAAO,EAAE,CAAA;IACzB,IAAI,GAAG,KAAK,CAAC;QAAE,OAAO,EAAE,CAAA;IACxB,IAAI,KAAK,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,EAAE,CAAC,MAAM,EAAE,IAAI,GAAG,EAAE,CAAC;IACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,EAAE,CAAC,EAAE;QAC7B,IAAI,IAAI,EAAE;YACT,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,IAAI,EAAE;gBACnB,IAAI,GAAG,KAAK,CAAC,EAAE;oBAAE,KAAK,GAAG,CAAC,CAAC;oBAAC,GAAG,GAAG,CAAC,CAAA;iBAAE;qBAChC,IAAI,KAAK,KAAK,CAAC,EAAE;oBACrB,GAAG,GAAG,CAAC,CAAA;oBACP,IAAI,GAAG,GAAG,GAAG,IAAI,GAAG,GAAG,KAAK,EAAE;wBAC7B,GAAG,GAAG,EAAE,CAAC,OAAO,CAAC,IAAI,EAAE,GAAG,CAAC,CAAA;wBAC3B,IAAI,GAAG,KAAK,CAAC,CAAC;4BAAE,OAAO,EAAE,CAAA;qBACzB;iBACD;qBAAM;oBACN,KAAK,GAAG,CAAC,CAAA;oBACT,IAAI,GAAG,GAAG,KAAK;wBAAE,OAAO,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,CAAA;iBACxC;gBACD,IAAI,GAAG,EAAE,CAAA;aACT;SACD;aACI,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,GAAG,EAAE;YAAC,IAAI,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC;YAAC,KAAK,GAAG,CAAC,CAAC;SAAC;aAC7C,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,GAAG,EAAE;YAAC,IAAI,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC;YAAC,KAAK,GAAG,CAAC,CAAC;SAAC;aAC7C,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,EAAE,CAAC,CAAC,GAAC,CAAC,CAAC,KAAK,GAAG;YAAE,OAAO,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,CAAA;KAClE;IACD,MAAM,QAAQ,GAAG,KAAK,KAAK,GAAG,IAAI,KAAK,GAAG,GAAG,IAAI,GAAG,GAAG,GAAG,CAAA;IAC1D,OAAO,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,CAAA;AACxC,CAAC,CAAA;AACD,MAAM,sBAAsB,GAAG,GAA8B,EAAE;IAC9D,IAAI,MAAM,GAAG,KAAK,CAAC;IACnB,OAAO,EAAE,CAAC,EAAE;QACX,QAAQ,EAAE,EAAE;YACX,KAAK,IAAI;gBAAE,MAAM,GAAG,IAAI,CAAC;gBAAC,OAAO,KAAK,CAAC;YACvC,KAAK,IAAI;gBAAE,MAAM,GAAG,KAAK,CAAC;gBAAC,OAAO,KAAK,CAAC;YACxC,OAAO,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC;SACxB;IACF,CAAC,CAAA;AACF,CAAC,CAAA;AACD;;;;;;;;;;;;;;;;;EAiBE;AACF,MAAM,eAAe,GAAG,sDAAsD,CAAC;AAClE,QAAA,QAAQ,GAAG,CAAC,CAAS,EAAY,EAAE,CAAC,CAAC;KAChD,OAAO,CAAC,eAAe,EAAE,MAAM,CAAC;KAChC,KAAK,CAAC,UAAU,CAAC;KACjB,GAAG,CAAC,WAAW,CAAC;KAChB,GAAG,CAAC,IAAI,CAAC;KACT,IAAI,CAAC,IAAI,CAAC;KACV,KAAK,CAAC,qCAAqC,CAAC;KAC5C,GAAG,CAAC,IAAI,CAAC;KACT,MAAM,CAAC,OAAO,CAAC;KACf,MAAM,CAAC,sBAAsB,EAAE,CAAC,CAAC;AAClC,uCAAuC;AACxC,kBAAe,gBAAQ,CAAC","sourcesContent":["const trim: ((s: string) => string) = Function.prototype.call.bind(''.trim)\nconst no_comments = (ln: string): string => {\n\tlet idx = ln.indexOf('//');\n\tif (idx === -1) return ln\n\tif (idx === 0) return ''\n\tlet start = 0, end = 0, len = ln.length, char = '';\n\tfor (let i = 0; i < len; ++i) {\n\t\tif (char) {\n\t\t\tif (ln[i] === char) {\n\t\t\t\tif (end !== 0) { start = i; end = 0 }\n\t\t\t\telse if (start !== 0) {\n\t\t\t\t\tend = i\n\t\t\t\t\tif (idx < end && idx > start) {\n\t\t\t\t\t\tidx = ln.indexOf('//', end)\n\t\t\t\t\t\tif (idx === -1) return ln\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tstart = i\n\t\t\t\t\tif (idx < start) return ln.slice(0, idx)\n\t\t\t\t}\n\t\t\t\tchar = ''\n\t\t\t}\n\t\t}\n\t\telse if (ln[i] === '\"') {char = ln[i]; start = i;}\n\t\telse if (ln[i] === \"'\") {char = ln[i]; start = i;}\n\t\telse if (ln[i] === '/' && ln[i+1] === '/') return ln.slice(0, idx)\n\t}\n\tconst in_value = start !== end && start < idx && end > idx\n\treturn in_value ? ln : ln.slice(0, idx)\n}\nconst no_multi_line_comments = (): ((tk: string) => boolean) => {\n\tlet inside = false;\n\treturn tk => {\n\t\tswitch (tk) {\n\t\t\tcase '/*': inside = true; return false;\n\t\t\tcase '*/': inside = false; return false;\n\t\t\tdefault: return !inside;\n\t\t}\n\t}\n}\n/*\nconst join_internal_strings = () => {\n\tlet str = '',\n\t\tinit = /^(\"([^\"]|\\\\\")*|'([^']|\\\\')*)$/,\n\t\tend = /^(([^\"]|\\\\\")*\"|([^']|\\\\')*')$/;\n\treturn (tokens: string[], val: string): string[] => {\n\t\tif (str.length) {\n\t\t\tstr += val\n\t\t\tif (end.test(val)) {\n\t\t\t\ttokens.push(str)\n\t\t\t\tstr = ''\n\t\t\t}\n\t\t} else if (init.test(val)) str = val\n\t\telse tokens.push(val)\n\t\treturn tokens\n\t}\n}\n*/\nconst token_retriever = /([;,{}()=:[\\]<>]|\\/\\*|\\*\\/|\"[^\"\\r\\n]*\"|'[^'\\r\\n]*')/g;\nexport const tokenise = (s: string): string[] => s\n\t.replace(token_retriever, ' $1 ')\n\t.split(/[\\r\\n]+/g)\n\t.map(no_comments)\n\t.map(trim)\n\t.join('\\n')\n\t.split(/(\"[^\"\\r\\n]*\"|'[^'\\r\\n]*'|\\s+|\\n+)/gm)\n\t.map(trim)\n\t.filter(Boolean)\n\t.filter(no_multi_line_comments());\n\t//.reduce(join_internal_strings(), []);\nexport default tokenise;\n"]}